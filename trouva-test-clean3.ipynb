{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('sizes.json', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_names=list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_types=[type(data._id[0]),\n",
    "type(data.__v[0]),\n",
    "type(data.created_at[0]),\n",
    "type(data.filter_label[0]),\n",
    "type(data.label[0]),\n",
    "type(data.old_label[0]),\n",
    "type(data.updated_at[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,len(column_names)):\n",
    "    print(column_names[i],column_types[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- dataframe has 7 columns/ 51210 lines\n",
    "- there are practically no missing values, except in column 'filter_label' where most of the values are missing. All other columns have no missing data\n",
    "- after an initial glance at the dataframe, we can make the following assumption/hypothesis: \n",
    "    - in columns 'created_at' and 'updated_at' the dictionary key holds reference to the information provided, and dictionary value holds the information (date / time of data entry)\n",
    "    - in columns 'created_at' and 'updated_at' dictionary key holds only one value \n",
    "    - columns' 'filter_label', 'label' and 'old_label' entries are lists which hold 1 or more values, with no particular pattern \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Potential Issues**\n",
    "- dataframe entries are objects which is not the most suitable type for data manipulation\n",
    "- as cells contain more than one value, it also makes descriptive analysis more complicated \n",
    "- columns' 'filter_label', 'label' and 'old_label' hold inconsistent data: for instance, we observe inconsistencies relating to data type, spelling, length of entry \n",
    "- as a result, the data presented in this format does not give an opportunity to control and maintain business processes relating to stock control/forecasting, sales analysis/forecasting and planning for elevated customer experience (smooth order process, attractive and relavent merchandise offering, personalised recommendations etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleansing Strategy**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **STEP 1: columns 'created_at' and 'updated_at'**\n",
    "\n",
    "- flatten the columns out: explore whether dictionary keys should become additional columns (depending on the information they present, and how many different key values we find), and assign dictionary values as cell values accordingly  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **STEP2: label columns** \n",
    "\n",
    "*Column 'old_label' suggests containing the original values/information submitted by the boutiques and poses an issue of not only varied spelling, but also the type of data (information) provided.* \n",
    "\n",
    "*Dealing with this column should be done iteratively, taking small steps, and focusing on attempt to cluster the data and find similarities/connections between the data entries, removing duplicates and finally identifying what information is presented: for instance, colour of the item, size of the item etc.* \n",
    "\n",
    "*Consequently, we may need to create additional columns which would hold different types of information, such has: 'size', 'colour', 'shape' of the item*   \n",
    "\n",
    "*Columns 'filter_label' and 'label' seem to hold the information resulting after some cleaning operations have been completed on 'old_label' column*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan**\n",
    "- separate dictionary keys and values \n",
    "- count the number of unique keys, and the number of unique values within a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_dic(df,col_name):\n",
    "    \"\"\"store dictionary keys and values of the column in separate list\"\"\"\n",
    "    keys=[]\n",
    "    values=[]\n",
    "    for index, row in data.iterrows():\n",
    "        item=row[col_name]\n",
    "        keys.extend(item.keys())\n",
    "        values.extend(item.values())\n",
    "    return keys, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_unique(item):\n",
    "    \"\"\"count unique keys and unique values within a column\"\"\"\n",
    "    unq_items=set(item)\n",
    "    return len(unq_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_col(data,col_name):\n",
    "    '''extract the dictionary value, and assign it cell value '''\n",
    "    for index,row in data.iterrows():\n",
    "        item=row[col_name]\n",
    "        value=list(item.values())    \n",
    "        data.loc[data.index[index], col_name]=str(value[0])\n",
    "    return data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def into_string(data):\n",
    "    for index,row in data.iterrows():\n",
    "        item=row['old_label']\n",
    "        item=', '.join(item)\n",
    "        item=re.sub('[^A-Za-z0-9,-]+', ' ', item)\n",
    "        data.loc[data.index[index], 'old_label']=item\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_infotype(data):\n",
    "    for index,row in data.iterrows():\n",
    "        item=row['old_label']\n",
    "        label=[]\n",
    "        \"\"\" split the sentence back into original sub-items, and assign the category for each item in the cell\"\"\"\n",
    "        result=item.replace(' ','').split(',')\n",
    "        for r in result:\n",
    "            if r.isdigit():\n",
    "\n",
    "                label.append('1')\n",
    "            elif r.isalpha():\n",
    "\n",
    "                label.extend('2')\n",
    "            else:\n",
    "\n",
    "                label.extend('3')\n",
    "        final_label=set(label)\n",
    "\n",
    "        \"\"\" if cell has more than one unique category, it needs to be assigned category 3 and cleaned further\"\"\"\n",
    "        if len(final_label)==1:\n",
    "            info_type1=list(final_label)[0]\n",
    "            \n",
    "            data.loc[index,['info_type']] = info_type1\n",
    "            \n",
    "        else:\n",
    "            info_type2='3'\n",
    "            data.loc[index,['info_type']] = info_type2\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_name='_id'\n",
    "col_name2='created_at'\n",
    "col_name3='updated_at'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_id, values_id= flatten_dic(data, col_name)\n",
    "keys_cr_at, values_cr_at=flatten_dic(data,col_name2)\n",
    "keys_updt_at, values_updt_at=flatten_dic(data,col_name3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('col _id unique keys:', check_unique(keys_id), ';' , 'col _id unique values:', check_unique(values_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('col created_at unique keys:', check_unique(keys_cr_at), ';' , 'col created_at unique values:', check_unique(values_cr_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('col updt_at unique keys:', check_unique(keys_updt_at), ';' , 'col updt_at unique values:', check_unique(values_updt_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Only 1 unique key value across all lines/per column\n",
    "- We can clean up each cell/per column by removing the dictionary key. The key relates to the current name of the column. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col(data, '_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col(data, col_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_col(data, col_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- 'created_at' and 'updated_at' columns point to the date of the entry and should by converted to datetime type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['created_at']  = pd.to_datetime(data['created_at'])\n",
    "data['updated_at']  = pd.to_datetime(data['updated_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Plan**\n",
    "- we observe, that each cell contains a list of items.\n",
    "- convert the list into a string, separated by ','\n",
    "- once the list is converted to a string, we can clean special characters as part of the first iterations of the cleaning exercise.\n",
    "- following the initial exploratin of the data set, I suggest keeping numerical and alphabetical characters, and \"-\", which is common characteristics of what would appear on merchandise label. \n",
    "\n",
    "---\n",
    "\n",
    "- identify if a cell contains numbers only, strings only, combination of both (could be within a string, could be within a cell) \n",
    "\n",
    "- based on that, assign each cell to a category:\n",
    "    * #1: numbers only  \n",
    "    * #2: alpha characters only\n",
    "    * #3 combination of both: either within a string, or, within the cell \n",
    "    \n",
    "- once the categories have been assigned, I suggest the following: \n",
    "    * #1: numbers only: through exploratory analysis identify if the data is interval/ratio \n",
    "    * #1: explore distribution, outliers, median/mean values, if applicable\n",
    "    * #1: info above could form further hypothesis what information this data may present. For instance, clothing                 sizes/shoe size?\n",
    "    \n",
    "    * #2: alpha characters only: explore distribution, unique values \n",
    "    * #2: form a word corpus, apply NLP techniques in order to: explore potential word clusters? identify word groups?          (verb, adjective, noun?) predict information type? (colour? pattern? location? etc?)             \n",
    "    * #2: experiment with NLP in order to clean the spelling looping through the dataframe line-by-line \n",
    "    \n",
    "- further cleaning iterations needed for category 3:\n",
    "    \n",
    "    * #3 further iterations may include: alternative splitting strategies (split by comma?/ space? ) \n",
    "    * #3 further iterations may include: after each splitting strategy check for the number of unique values (do any          of the words repeat throughout the dataframe?)  \n",
    "    * #3 further iterations may include identifying lines where combination of alpha / numerical characters are within          one string and/or within once cell? Explore unique values/ distribution \n",
    "    * #3 further iterations may include: explore how strings are distributed across the dataframe before any splitting          strategies(ie, analyse all lines as they are, just after assigning them to category 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=into_string(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if all lines have been converted to string \n",
    "#for index,row in data.iterrows():\n",
    "    #item=row['old_label']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create and additional column ['info_type'] which will indicate what type of infomation is presented in column old_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['info_type'] = \"\"\n",
    "data['info_type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_infotype(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "5        3\n",
       "6        3\n",
       "7        3\n",
       "8        1\n",
       "9        1\n",
       "10       3\n",
       "11       2\n",
       "12       2\n",
       "13       2\n",
       "14       2\n",
       "15       2\n",
       "16       3\n",
       "17       2\n",
       "18       3\n",
       "19       3\n",
       "20       3\n",
       "21       2\n",
       "22       3\n",
       "23       3\n",
       "24       3\n",
       "25       3\n",
       "26       3\n",
       "27       2\n",
       "28       3\n",
       "29       3\n",
       "        ..\n",
       "51180    3\n",
       "51181    3\n",
       "51182    3\n",
       "51183    3\n",
       "51184    3\n",
       "51185    3\n",
       "51186    3\n",
       "51187    3\n",
       "51188    3\n",
       "51189    3\n",
       "51190    3\n",
       "51191    3\n",
       "51192    3\n",
       "51193    3\n",
       "51194    3\n",
       "51195    3\n",
       "51196    3\n",
       "51197    3\n",
       "51198    3\n",
       "51199    3\n",
       "51200    3\n",
       "51201    3\n",
       "51202    3\n",
       "51203    3\n",
       "51204    3\n",
       "51205    3\n",
       "51206    3\n",
       "51207    3\n",
       "51208    3\n",
       "51209    3\n",
       "Name: info_type, Length: 51210, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(data['info_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-75852c38e8fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'info_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3079\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3080\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   3082\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3083\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1895\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1896\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1898\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mhist\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   6178\u001b[0m             \u001b[0mxmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6179\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6180\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6181\u001b[0m                     \u001b[0mxmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6182\u001b[0m                     \u001b[0mxmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
